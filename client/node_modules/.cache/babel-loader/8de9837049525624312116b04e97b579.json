{"ast":null,"code":"'use strict';\n\nconst common = require('./common');\n\nconst BulkOperationBase = common.BulkOperationBase;\nconst Batch = common.Batch;\nconst bson = common.bson;\n\nconst utils = require('../utils');\n\nconst toError = utils.toError;\n/**\r\n * Add to internal list of Operations\r\n *\r\n * @ignore\r\n * @param {OrderedBulkOperation} bulkOperation\r\n * @param {number} docType number indicating the document type\r\n * @param {object} document\r\n * @return {OrderedBulkOperation}\r\n */\n\nfunction addToOperationsList(bulkOperation, docType, document) {\n  // Get the bsonSize\n  const bsonSize = bson.calculateObjectSize(document, {\n    checkKeys: false,\n    // Since we don't know what the user selected for BSON options here,\n    // err on the safe side, and check the size with ignoreUndefined: false.\n    ignoreUndefined: false\n  }); // Throw error if the doc is bigger than the max BSON size\n\n  if (bsonSize >= bulkOperation.s.maxBsonObjectSize) throw toError('document is larger than the maximum size ' + bulkOperation.s.maxBsonObjectSize); // Create a new batch object if we don't have a current one\n\n  if (bulkOperation.s.currentBatch == null) bulkOperation.s.currentBatch = new Batch(docType, bulkOperation.s.currentIndex);\n  const maxKeySize = bulkOperation.s.maxKeySize; // Check if we need to create a new batch\n\n  if ( // New batch if we exceed the max batch op size\n  bulkOperation.s.currentBatchSize + 1 >= bulkOperation.s.maxWriteBatchSize || // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n  // since we can't sent an empty batch\n  bulkOperation.s.currentBatchSize > 0 && bulkOperation.s.currentBatchSizeBytes + maxKeySize + bsonSize >= bulkOperation.s.maxBatchSizeBytes || // New batch if the new op does not have the same op type as the current batch\n  bulkOperation.s.currentBatch.batchType !== docType) {\n    // Save the batch to the execution stack\n    bulkOperation.s.batches.push(bulkOperation.s.currentBatch); // Create a new batch\n\n    bulkOperation.s.currentBatch = new Batch(docType, bulkOperation.s.currentIndex); // Reset the current size trackers\n\n    bulkOperation.s.currentBatchSize = 0;\n    bulkOperation.s.currentBatchSizeBytes = 0;\n  }\n\n  if (docType === common.INSERT) {\n    bulkOperation.s.bulkResult.insertedIds.push({\n      index: bulkOperation.s.currentIndex,\n      _id: document._id\n    });\n  } // We have an array of documents\n\n\n  if (Array.isArray(document)) {\n    throw toError('operation passed in cannot be an Array');\n  }\n\n  bulkOperation.s.currentBatch.originalIndexes.push(bulkOperation.s.currentIndex);\n  bulkOperation.s.currentBatch.operations.push(document);\n  bulkOperation.s.currentBatchSize += 1;\n  bulkOperation.s.currentBatchSizeBytes += maxKeySize + bsonSize;\n  bulkOperation.s.currentIndex += 1; // Return bulkOperation\n\n  return bulkOperation;\n}\n/**\r\n * Create a new OrderedBulkOperation instance (INTERNAL TYPE, do not instantiate directly)\r\n * @class\r\n * @extends BulkOperationBase\r\n * @property {number} length Get the number of operations in the bulk.\r\n * @return {OrderedBulkOperation} a OrderedBulkOperation instance.\r\n */\n\n\nclass OrderedBulkOperation extends BulkOperationBase {\n  constructor(topology, collection, options) {\n    options = options || {};\n    options = Object.assign(options, {\n      addToOperationsList\n    });\n    super(topology, collection, options, true);\n  }\n\n}\n/**\r\n * Returns an unordered batch object\r\n * @ignore\r\n */\n\n\nfunction initializeOrderedBulkOp(topology, collection, options) {\n  return new OrderedBulkOperation(topology, collection, options);\n}\n\ninitializeOrderedBulkOp.OrderedBulkOperation = OrderedBulkOperation;\nmodule.exports = initializeOrderedBulkOp;\nmodule.exports.Bulk = OrderedBulkOperation;","map":{"version":3,"sources":["C:/Users/Tanja Aakerholt/Documents/GitHub/portfolio2/client/node_modules/mongodb/lib/bulk/ordered.js"],"names":["common","require","BulkOperationBase","Batch","bson","utils","toError","addToOperationsList","bulkOperation","docType","document","bsonSize","calculateObjectSize","checkKeys","ignoreUndefined","s","maxBsonObjectSize","currentBatch","currentIndex","maxKeySize","currentBatchSize","maxWriteBatchSize","currentBatchSizeBytes","maxBatchSizeBytes","batchType","batches","push","INSERT","bulkResult","insertedIds","index","_id","Array","isArray","originalIndexes","operations","OrderedBulkOperation","constructor","topology","collection","options","Object","assign","initializeOrderedBulkOp","module","exports","Bulk"],"mappings":"AAAA;;AAEA,MAAMA,MAAM,GAAGC,OAAO,CAAC,UAAD,CAAtB;;AACA,MAAMC,iBAAiB,GAAGF,MAAM,CAACE,iBAAjC;AACA,MAAMC,KAAK,GAAGH,MAAM,CAACG,KAArB;AACA,MAAMC,IAAI,GAAGJ,MAAM,CAACI,IAApB;;AACA,MAAMC,KAAK,GAAGJ,OAAO,CAAC,UAAD,CAArB;;AACA,MAAMK,OAAO,GAAGD,KAAK,CAACC,OAAtB;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,SAASC,mBAAT,CAA6BC,aAA7B,EAA4CC,OAA5C,EAAqDC,QAArD,EAA+D;AAC7D;AACA,QAAMC,QAAQ,GAAGP,IAAI,CAACQ,mBAAL,CAAyBF,QAAzB,EAAmC;AAClDG,IAAAA,SAAS,EAAE,KADuC;AAGlD;AACA;AACAC,IAAAA,eAAe,EAAE;AALiC,GAAnC,CAAjB,CAF6D,CAU7D;;AACA,MAAIH,QAAQ,IAAIH,aAAa,CAACO,CAAd,CAAgBC,iBAAhC,EACE,MAAMV,OAAO,CAAC,8CAA8CE,aAAa,CAACO,CAAd,CAAgBC,iBAA/D,CAAb,CAZ2D,CAc7D;;AACA,MAAIR,aAAa,CAACO,CAAd,CAAgBE,YAAhB,IAAgC,IAApC,EACET,aAAa,CAACO,CAAd,CAAgBE,YAAhB,GAA+B,IAAId,KAAJ,CAAUM,OAAV,EAAmBD,aAAa,CAACO,CAAd,CAAgBG,YAAnC,CAA/B;AAEF,QAAMC,UAAU,GAAGX,aAAa,CAACO,CAAd,CAAgBI,UAAnC,CAlB6D,CAoB7D;;AACA,OACE;AACAX,EAAAA,aAAa,CAACO,CAAd,CAAgBK,gBAAhB,GAAmC,CAAnC,IAAwCZ,aAAa,CAACO,CAAd,CAAgBM,iBAAxD,IACA;AACA;AACCb,EAAAA,aAAa,CAACO,CAAd,CAAgBK,gBAAhB,GAAmC,CAAnC,IACCZ,aAAa,CAACO,CAAd,CAAgBO,qBAAhB,GAAwCH,UAAxC,GAAqDR,QAArD,IACEH,aAAa,CAACO,CAAd,CAAgBQ,iBALpB,IAMA;AACAf,EAAAA,aAAa,CAACO,CAAd,CAAgBE,YAAhB,CAA6BO,SAA7B,KAA2Cf,OAT7C,EAUE;AACA;AACAD,IAAAA,aAAa,CAACO,CAAd,CAAgBU,OAAhB,CAAwBC,IAAxB,CAA6BlB,aAAa,CAACO,CAAd,CAAgBE,YAA7C,EAFA,CAIA;;AACAT,IAAAA,aAAa,CAACO,CAAd,CAAgBE,YAAhB,GAA+B,IAAId,KAAJ,CAAUM,OAAV,EAAmBD,aAAa,CAACO,CAAd,CAAgBG,YAAnC,CAA/B,CALA,CAOA;;AACAV,IAAAA,aAAa,CAACO,CAAd,CAAgBK,gBAAhB,GAAmC,CAAnC;AACAZ,IAAAA,aAAa,CAACO,CAAd,CAAgBO,qBAAhB,GAAwC,CAAxC;AACD;;AAED,MAAIb,OAAO,KAAKT,MAAM,CAAC2B,MAAvB,EAA+B;AAC7BnB,IAAAA,aAAa,CAACO,CAAd,CAAgBa,UAAhB,CAA2BC,WAA3B,CAAuCH,IAAvC,CAA4C;AAC1CI,MAAAA,KAAK,EAAEtB,aAAa,CAACO,CAAd,CAAgBG,YADmB;AAE1Ca,MAAAA,GAAG,EAAErB,QAAQ,CAACqB;AAF4B,KAA5C;AAID,GAhD4D,CAkD7D;;;AACA,MAAIC,KAAK,CAACC,OAAN,CAAcvB,QAAd,CAAJ,EAA6B;AAC3B,UAAMJ,OAAO,CAAC,wCAAD,CAAb;AACD;;AAEDE,EAAAA,aAAa,CAACO,CAAd,CAAgBE,YAAhB,CAA6BiB,eAA7B,CAA6CR,IAA7C,CAAkDlB,aAAa,CAACO,CAAd,CAAgBG,YAAlE;AACAV,EAAAA,aAAa,CAACO,CAAd,CAAgBE,YAAhB,CAA6BkB,UAA7B,CAAwCT,IAAxC,CAA6ChB,QAA7C;AACAF,EAAAA,aAAa,CAACO,CAAd,CAAgBK,gBAAhB,IAAoC,CAApC;AACAZ,EAAAA,aAAa,CAACO,CAAd,CAAgBO,qBAAhB,IAAyCH,UAAU,GAAGR,QAAtD;AACAH,EAAAA,aAAa,CAACO,CAAd,CAAgBG,YAAhB,IAAgC,CAAhC,CA3D6D,CA6D7D;;AACA,SAAOV,aAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAM4B,oBAAN,SAAmClC,iBAAnC,CAAqD;AACnDmC,EAAAA,WAAW,CAACC,QAAD,EAAWC,UAAX,EAAuBC,OAAvB,EAAgC;AACzCA,IAAAA,OAAO,GAAGA,OAAO,IAAI,EAArB;AACAA,IAAAA,OAAO,GAAGC,MAAM,CAACC,MAAP,CAAcF,OAAd,EAAuB;AAAEjC,MAAAA;AAAF,KAAvB,CAAV;AAEA,UAAM+B,QAAN,EAAgBC,UAAhB,EAA4BC,OAA5B,EAAqC,IAArC;AACD;;AANkD;AASrD;AACA;AACA;AACA;;;AACA,SAASG,uBAAT,CAAiCL,QAAjC,EAA2CC,UAA3C,EAAuDC,OAAvD,EAAgE;AAC9D,SAAO,IAAIJ,oBAAJ,CAAyBE,QAAzB,EAAmCC,UAAnC,EAA+CC,OAA/C,CAAP;AACD;;AAEDG,uBAAuB,CAACP,oBAAxB,GAA+CA,oBAA/C;AACAQ,MAAM,CAACC,OAAP,GAAiBF,uBAAjB;AACAC,MAAM,CAACC,OAAP,CAAeC,IAAf,GAAsBV,oBAAtB","sourcesContent":["'use strict';\r\n\r\nconst common = require('./common');\r\nconst BulkOperationBase = common.BulkOperationBase;\r\nconst Batch = common.Batch;\r\nconst bson = common.bson;\r\nconst utils = require('../utils');\r\nconst toError = utils.toError;\r\n\r\n/**\r\n * Add to internal list of Operations\r\n *\r\n * @ignore\r\n * @param {OrderedBulkOperation} bulkOperation\r\n * @param {number} docType number indicating the document type\r\n * @param {object} document\r\n * @return {OrderedBulkOperation}\r\n */\r\nfunction addToOperationsList(bulkOperation, docType, document) {\r\n  // Get the bsonSize\r\n  const bsonSize = bson.calculateObjectSize(document, {\r\n    checkKeys: false,\r\n\r\n    // Since we don't know what the user selected for BSON options here,\r\n    // err on the safe side, and check the size with ignoreUndefined: false.\r\n    ignoreUndefined: false\r\n  });\r\n\r\n  // Throw error if the doc is bigger than the max BSON size\r\n  if (bsonSize >= bulkOperation.s.maxBsonObjectSize)\r\n    throw toError('document is larger than the maximum size ' + bulkOperation.s.maxBsonObjectSize);\r\n\r\n  // Create a new batch object if we don't have a current one\r\n  if (bulkOperation.s.currentBatch == null)\r\n    bulkOperation.s.currentBatch = new Batch(docType, bulkOperation.s.currentIndex);\r\n\r\n  const maxKeySize = bulkOperation.s.maxKeySize;\r\n\r\n  // Check if we need to create a new batch\r\n  if (\r\n    // New batch if we exceed the max batch op size\r\n    bulkOperation.s.currentBatchSize + 1 >= bulkOperation.s.maxWriteBatchSize ||\r\n    // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\r\n    // since we can't sent an empty batch\r\n    (bulkOperation.s.currentBatchSize > 0 &&\r\n      bulkOperation.s.currentBatchSizeBytes + maxKeySize + bsonSize >=\r\n        bulkOperation.s.maxBatchSizeBytes) ||\r\n    // New batch if the new op does not have the same op type as the current batch\r\n    bulkOperation.s.currentBatch.batchType !== docType\r\n  ) {\r\n    // Save the batch to the execution stack\r\n    bulkOperation.s.batches.push(bulkOperation.s.currentBatch);\r\n\r\n    // Create a new batch\r\n    bulkOperation.s.currentBatch = new Batch(docType, bulkOperation.s.currentIndex);\r\n\r\n    // Reset the current size trackers\r\n    bulkOperation.s.currentBatchSize = 0;\r\n    bulkOperation.s.currentBatchSizeBytes = 0;\r\n  }\r\n\r\n  if (docType === common.INSERT) {\r\n    bulkOperation.s.bulkResult.insertedIds.push({\r\n      index: bulkOperation.s.currentIndex,\r\n      _id: document._id\r\n    });\r\n  }\r\n\r\n  // We have an array of documents\r\n  if (Array.isArray(document)) {\r\n    throw toError('operation passed in cannot be an Array');\r\n  }\r\n\r\n  bulkOperation.s.currentBatch.originalIndexes.push(bulkOperation.s.currentIndex);\r\n  bulkOperation.s.currentBatch.operations.push(document);\r\n  bulkOperation.s.currentBatchSize += 1;\r\n  bulkOperation.s.currentBatchSizeBytes += maxKeySize + bsonSize;\r\n  bulkOperation.s.currentIndex += 1;\r\n\r\n  // Return bulkOperation\r\n  return bulkOperation;\r\n}\r\n\r\n/**\r\n * Create a new OrderedBulkOperation instance (INTERNAL TYPE, do not instantiate directly)\r\n * @class\r\n * @extends BulkOperationBase\r\n * @property {number} length Get the number of operations in the bulk.\r\n * @return {OrderedBulkOperation} a OrderedBulkOperation instance.\r\n */\r\nclass OrderedBulkOperation extends BulkOperationBase {\r\n  constructor(topology, collection, options) {\r\n    options = options || {};\r\n    options = Object.assign(options, { addToOperationsList });\r\n\r\n    super(topology, collection, options, true);\r\n  }\r\n}\r\n\r\n/**\r\n * Returns an unordered batch object\r\n * @ignore\r\n */\r\nfunction initializeOrderedBulkOp(topology, collection, options) {\r\n  return new OrderedBulkOperation(topology, collection, options);\r\n}\r\n\r\ninitializeOrderedBulkOp.OrderedBulkOperation = OrderedBulkOperation;\r\nmodule.exports = initializeOrderedBulkOp;\r\nmodule.exports.Bulk = OrderedBulkOperation;\r\n"]},"metadata":{},"sourceType":"script"}